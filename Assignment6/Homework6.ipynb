{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAMES: Timothy Barao, Marlan McInnes-Taylor\n",
    "# FSUIDS: tjb13b, mm05f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FSA:\n",
    "    def __init__(self, xt, yt, xv, yv):\n",
    "        self.load_data(xt, yt, xv, yv)\n",
    "        \n",
    "        self.s = 0.001\n",
    "        self.u = 50 #100\n",
    "        self.N_iter = 500\n",
    "        self.lr = 20       #Try 20\n",
    "\n",
    "        #self.B_0 = 0\n",
    " \n",
    "        self.M = self.x_t.shape[1]\n",
    "        self.N = self.x_t.shape[0]\n",
    "        self.B = np.zeros(self.M)\n",
    "        # self.k = [10, 30, 100, 300, 500]\n",
    "        \n",
    "        self.losses = []\n",
    "    \n",
    "    \n",
    "    def load_data(self, x_train_file, y_train_file, x_valid_file, y_valid_file):\n",
    "        with open(x_train_file) as file:\n",
    "            \n",
    "            if \"dexter\" in x_train_file:\n",
    "                self.x_t = pd.read_csv(file, delim_whitespace=False, header=None)\n",
    "            else:    \n",
    "                self.x_t = pd.read_csv(file, delim_whitespace=True, header=None)\n",
    "            self.x_t = self.x_t.to_numpy(dtype=np.float64)\n",
    "\n",
    "        with open(y_train_file) as file:\n",
    "            self.y_t = pd.read_csv(file, header=None)\n",
    "            self.y_t = self.y_t.to_numpy(dtype=np.float64)\n",
    "\n",
    "        with open(x_valid_file) as file:\n",
    "            \n",
    "            if \"dexter\" in x_valid_file:\n",
    "                self.x_v = pd.read_csv(file, delim_whitespace=False, header=None)\n",
    "            else:    \n",
    "                self.x_v = pd.read_csv(file, delim_whitespace=True, header=None)\n",
    "            self.x_v = self.x_v.to_numpy(dtype=np.float64)\n",
    "            \n",
    "        with open(y_valid_file) as file:\n",
    "            self.y_v = pd.read_csv(file, header=None)\n",
    "            self.y_v = self.y_v.to_numpy(dtype=np.float64)\n",
    "\n",
    "        self.N = self.x_t.shape[0]   # Rows\n",
    "        self.M = self.x_t.shape[1]   # Columns \n",
    "\n",
    "        # Standardize data\n",
    "        for i in range(0, self.M):\n",
    "            if (not np.any(self.x_v[:, i])):\n",
    "                self.x_v[:, i].fill(0)\n",
    "            else:  \n",
    "                self.x_v[:, i] = (self.x_v[:, i] - np.mean(self.x_v[:, i]))/(np.std(self.x_v[:, i]))\n",
    "\n",
    "            if(not np.any(self.x_t[:, i])):\n",
    "                self.x_t[:, i].fill(0)\n",
    "            else:\n",
    "                self.x_t[:, i] = (self.x_t[:, i] - np.mean(self.x_t[:, i]))/(np.std(self.x_t[:, i]))  \n",
    "        \n",
    "        self.x_v = np.insert(self.x_v, 0, 1, axis=1)\n",
    "        self.x_t = np.insert(self.x_t, 0, 1, axis=1)\n",
    "\n",
    "                \n",
    "    def gradient_update(self):\n",
    "        loss = self.loss()\n",
    "        # self.B = self.B - self.lr * self.loss()\n",
    "        self.B = self.B - self.lr * loss\n",
    "        return self.B, loss\n",
    "    \n",
    "    def loss(self):\n",
    "        #temp = np.sum(self.x_t*self.B, axis=1)\n",
    "        temp = np.dot(self.x_t, self.B)\n",
    "        temp = np.dot(temp, self.y_t.flatten())\n",
    "        if temp > 1:\n",
    "            temp = 0\n",
    "        else:\n",
    "            var = (temp - 1)**2\n",
    "            temp = np.log(1 + var)\n",
    "        '''\n",
    "        for index in range(0, len(temp)):\n",
    "            if temp[index] > 1:\n",
    "                temp[index] = 0\n",
    "            else:\n",
    "                var = (temp[index] - 1)**2\n",
    "                temp[index] = np.log(1 + var)\n",
    "        '''            \n",
    "        temp += self.s * LA.norm(self.B, 2)        \n",
    "        temp /= self.N \n",
    "        return temp\n",
    "        # 0            if x > 1\n",
    "        # ln(1+(x-1)^2) else\n",
    "    \n",
    "    def predict(self):\n",
    "        '''\n",
    "        xB = np.matmul(self.x_t, self.B)\n",
    "        yPred = np.sign(xB)\n",
    "        print(\"Pred: \", yPred)\n",
    "        print(\"y_t: \", self.y_t)\n",
    "        print(\"xB: \", xB)'''\n",
    "        \n",
    "        \n",
    "        xB = np.matmul(self.x_t, self.B)\n",
    "        yPred = np.sign(xB)\n",
    "        trainAcc = 1- np.mean(yPred == self.y_t.flatten().T)\n",
    "        \n",
    "        xB = np.matmul(self.x_v, self.B)\n",
    "        yPred = np.sign(xB)\n",
    "        testAcc = 1 - np.mean(yPred == self.y_v.flatten().T)\n",
    "        return trainAcc, testAcc\n",
    "    \n",
    "    def train(self, k):\n",
    "        mPrev = self.M\n",
    "        for i in range(0, self.N_iter):\n",
    "            if k == 30:\n",
    "                B, loss = self.gradient_update()\n",
    "                self.losses.append(loss)\n",
    "            else:\n",
    "                self.gradient_update()\n",
    "            \n",
    "            temp = (self.N_iter - 2 * i)/(2 * i * self.u + self.N_iter)\n",
    "            temp = max(0., temp)\n",
    "            mi = k + (self.M - k) * temp\n",
    "            mi = int(mi)\n",
    "            \n",
    "            if mi < mPrev:\n",
    "                indc = np.absolute(self.B)\n",
    "                sort = np.argsort(indc)\n",
    "                sort = sort[-mi:]\n",
    "                self.B=self.B[sort]\n",
    "                self.x_t=(self.x_t.T[sort]).T\n",
    "                self.x_v=(self.x_v.T[sort]).T\n",
    "                mPrev = mi\n",
    "                \n",
    "            #print(\"Iteration: \", i, \"M_i: \", int(mi))\n",
    "            #print('Non-zero count: ', np.count_nonzero(self.B))\n",
    "            \n",
    "        return 0\n",
    "    \n",
    "    \n",
    "    def print_features(self):\n",
    "        print(\"X_train Objs: \", self.x_t.shape[0], \"X_train Feats: \", self.x_t.shape[1])\n",
    "        print(\"Y_train Objs: \", self.y_t.shape[0])\n",
    "\n",
    "        print(\"\\nX_valid Objs: \", self.x_v.shape[0], \"X_valid Feats: \", self.x_v.shape[1])\n",
    "        print(\"Y_valid Objs: \", self.y_v.shape[0])\n",
    "\n",
    "                \n",
    "        #self.x_t, self.y_t, self.x_v, self.y_v = x_train, y_train, x_valid, y_valid \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select k = [10, 30, 100, 300] features\n",
    "# Plot the training loss vs iteration number k = 10\n",
    "# Report in Table the misclassification errors on the training and testing set for models obtained for all k\n",
    "# Plot the misclassification error on the training set and testing set vs k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = [10, 30, 100, 300, 500]\n",
    "trainErrors = []\n",
    "testErrors = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Madelon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_file = \"../data/MADELON/madelon_train.data\"\n",
    "y_train_file = \"../data/MADELON/madelon_train.labels\"\n",
    "\n",
    "x_valid_file = \"../data/MADELON/madelon_valid.data\"\n",
    "y_valid_file = \"../data/MADELON/madelon_valid.labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Errors:  [52.05, 50.45, 51.75, 48.7, 49.2]\n",
      "Test Errors:  [51.5, 50.83, 50.17, 45.83, 48.5]\n"
     ]
    }
   ],
   "source": [
    "#model = FSA(x_train_file, y_train_file, x_valid_file, y_valid_file)\n",
    "#iterations = np.arange(0, model.N_iter)\n",
    "for k in K:\n",
    "    #model.print_features()\n",
    "    model = FSA(x_train_file, y_train_file, x_valid_file, y_valid_file)\n",
    "    xVals = np.arange(0, model.N_iter)\n",
    "    model.train(k)\n",
    "    trainAccuracy, testAccuracy = model.predict()\n",
    "    trainErrors.append(round((1-trainAccuracy) * 100, 2))\n",
    "    testErrors.append(round((1-testAccuracy) * 100, 2))\n",
    "print(\"Train Errors: \", trainErrors)\n",
    "print(\"Test Errors: \", testErrors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (1,) and (5,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-befa1eb6f7e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainErrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestErrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Misclassification Error vs Number of Features'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2787\u001b[0m     return gca().plot(\n\u001b[1;32m   2788\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2789\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1664\u001b[0m         \"\"\"\n\u001b[1;32m   1665\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1666\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1667\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 270\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (1,) and (5,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(k, trainErrors, linestyle='-', marker='o', color='r', label='Train')\n",
    "plt.plot(k, testErrors, linestyle='-', marker='o', color='b', label='Test')\n",
    "plt.grid(True)\n",
    "plt.xticks(k)\n",
    "plt.title('Misclassification Error vs Number of Features')\n",
    "plt.xlabel('Number of Features (k)')\n",
    "plt.ylabel('Misclassification Error (%)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(xVals, model.losses, linestyle='-', marker='o', color='g')\n",
    "plt.grid(True)\n",
    "plt.xticks(xVals)\n",
    "plt.title('Training Loss vs Iteration Number k=30')\n",
    "plt.xlabel('Iteration Number (i)')\n",
    "plt.ylabel('Training Loss (L_i)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k, trainErrors, linestyle='-', marker='o', color='r', label='Train')\n",
    "plt.plot(k, testErrors, linestyle='-', marker='o', color='b', label='Test')\n",
    "plt.grid(True)\n",
    "plt.xticks(k)\n",
    "plt.title('Misclassification Error vs Number of Features')\n",
    "plt.xlabel('Number of Features (k)')\n",
    "plt.ylabel('Misclassification Error (%)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorTableMadelon = pd.DataFrame({\"Training Error (%)\":[0, 0, 0, 0, 0], \"Test Error (%)\":[0, 0, 0, 0, 0]}, index=K)\n",
    "errorTableMadelon.index.name = \"N Features\"\n",
    "for k, trainErr, testErr in zip(K, trainErrors, testErrors):\n",
    "    errorTableMadelon.loc[k, 'Training Error (%)'] = trainErr\n",
    "    errorTableMadelon.loc[k, 'Test Error (%)'] = testErr\n",
    "    \n",
    "errorTableMadelon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainErrors.clear()\n",
    "testErrors.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dexter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_file = \"../data/dexter/dexter_train.csv\"\n",
    "y_train_file = \"../data/dexter/dexter_train.labels\"\n",
    "\n",
    "x_valid_file = \"../data/dexter/dexter_valid.csv\"\n",
    "y_valid_file = \"../data/dexter/dexter_valid.labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FSA(x_train_file, y_train_file, x_valid_file, y_valid_file)\n",
    "model.print_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xVals, model.losses, linestyle='-', marker='o', color='g')\n",
    "plt.grid(True)\n",
    "plt.xticks(xVals)\n",
    "plt.title('Training Loss vs Iteration Number k=30')\n",
    "plt.xlabel('Iteration Number (i)')\n",
    "plt.ylabel('Training Loss (L_i)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k, trainErrors, linestyle='-', marker='o', color='r', label='Train')\n",
    "plt.plot(k, testErrors, linestyle='-', marker='o', color='b', label='Test')\n",
    "plt.grid(True)\n",
    "plt.xticks(k)\n",
    "plt.title('Misclassification Error vs Number of Features')\n",
    "plt.xlabel('Number of Features (k)')\n",
    "plt.ylabel('Misclassification Error (%)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorTableDexter = pd.DataFrame({\"Training Error (%)\":[0, 0, 0, 0, 0], \"Test Error (%)\":[0, 0, 0, 0, 0]}, index=K)\n",
    "errorTableDexter.index.name = \"N Features\"\n",
    "for k, trainErr, testErr in zip(K, trainErrors, testErrors):\n",
    "    errorTableDexter.loc[k, 'Training Error (%)'] = trainErr\n",
    "    errorTableDexter.loc[k, 'Test Error (%)'] = testErr\n",
    "    \n",
    "errorTableMadelon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainErrors.clear()\n",
    "testErrors.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gisette "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_file = \"../data/Gisette/gisette_train.data\"\n",
    "y_train_file = \"../data/Gisette/gisette_train.labels\"\n",
    "\n",
    "x_valid_file = \"../data/Gisette/gisette_valid.data\"\n",
    "y_valid_file = \"../data/Gisette/gisette_valid.labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FSA(x_train_file, y_train_file, x_valid_file, y_valid_file)\n",
    "model.print_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xVals, model.losses, linestyle='-', marker='o', color='g')\n",
    "plt.grid(True)\n",
    "plt.xticks(xVals)\n",
    "plt.title('Training Loss vs Iteration Number k=30')\n",
    "plt.xlabel('Iteration Number (i)')\n",
    "plt.ylabel('Training Loss (L_i)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k, trainErrors, linestyle='-', marker='o', color='r', label='Train')\n",
    "plt.plot(k, testErrors, linestyle='-', marker='o', color='b', label='Test')\n",
    "plt.grid(True)\n",
    "plt.xticks(k)\n",
    "plt.title('Misclassification Error vs Number of Features')\n",
    "plt.xlabel('Number of Features (k)')\n",
    "plt.ylabel('Misclassification Error (%)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorTableGisette = pd.DataFrame({\"Training Error (%)\":[0, 0, 0, 0, 0], \"Test Error (%)\":[0, 0, 0, 0, 0]}, index=K)\n",
    "errorTableGisette.index.name = \"N Features\"\n",
    "for k, trainErr, testErr in zip(K, trainErrors, testErrors):\n",
    "    errorTableGisette.loc[k, 'Training Error (%)'] = trainErr\n",
    "    errorTableGisette.loc[k, 'Test Error (%)'] = testErr\n",
    "    \n",
    "errorTableMadelon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commented Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Load Data:    \n",
    "    # x_valid = np.insert(x_valid, 0, 1, axis=1)\n",
    "    # x_train = np.insert(x_train, 0, 1, axis=1)\n",
    "\n",
    "    #y_valid = np.where(y_valid == -1, 0, y_valid)  \n",
    "    #y_train = np.where(y_train == -1, 0, y_train)\n",
    "    \n",
    "                '''\n",
    "                while np.count_nonzero(self.B) > mi:\n",
    "                    minimum = np.amin(self.B, where=np.where(self.B != 0))\n",
    "                    indices = np.where(self.B == minimum)\n",
    "                    for index in indices:\n",
    "                        self.B[index] = 0\n",
    "                        if np.count_nonzero(self.B) == mi:\n",
    "                            break    \n",
    "                mPrev = mi\n",
    "            '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
