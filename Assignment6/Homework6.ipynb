{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAMES: Timothy Barao, Marlan McInnes-Taylor\n",
    "# FSUIDS: tjb13b, mm05f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FSA:\n",
    "    def __init__(self, xt, yt, xv, yv):\n",
    "        self.load_data(xt, yt, xv, yv)\n",
    "        \n",
    "        self.s = 0.001\n",
    "        self.u = 50 #100\n",
    "        self.N_iter = 500\n",
    "        self.lr = 0.01         #Try 20\n",
    "\n",
    "        #self.B_0 = 0\n",
    " \n",
    "        self.M = self.x_t.shape[1]\n",
    "        self.N = self.x_t.shape[0]\n",
    "        self.B = np.zeros(self.M)\n",
    "        # self.k = [10, 30, 100, 300, 500]\n",
    "        \n",
    "        self.losses = []\n",
    "    \n",
    "    \n",
    "    def load_data(self, x_train_file, y_train_file, x_valid_file, y_valid_file):\n",
    "        with open(x_train_file) as file:\n",
    "            \n",
    "            if \"dexter\" in x_train_file:\n",
    "                self.x_t = pd.read_csv(file, delim_whitespace=False, header=None)\n",
    "            else:    \n",
    "                self.x_t = pd.read_csv(file, delim_whitespace=True, header=None)\n",
    "            self.x_t = self.x_t.to_numpy(dtype=np.float64)\n",
    "\n",
    "        with open(y_train_file) as file:\n",
    "            self.y_t = pd.read_csv(file, header=None)\n",
    "            self.y_t = self.y_t.to_numpy(dtype=np.float64)\n",
    "\n",
    "        with open(x_valid_file) as file:\n",
    "            \n",
    "            if \"dexter\" in x_valid_file:\n",
    "                self.x_v = pd.read_csv(file, delim_whitespace=False, header=None)\n",
    "            else:    \n",
    "                self.x_v = pd.read_csv(file, delim_whitespace=True, header=None)\n",
    "            self.x_v = self.x_v.to_numpy(dtype=np.float64)\n",
    "            \n",
    "        with open(y_valid_file) as file:\n",
    "            self.y_v = pd.read_csv(file, header=None)\n",
    "            self.y_v = self.y_v.to_numpy(dtype=np.float64)\n",
    "\n",
    "        self.N = self.x_t.shape[0]   # Rows\n",
    "        self.M = self.x_t.shape[1]   # Columns \n",
    "\n",
    "        # Standardize data\n",
    "        for i in range(0, self.M):\n",
    "            if (not np.any(self.x_v[:, i])):\n",
    "                self.x_v[:, i].fill(0)\n",
    "            else:  \n",
    "                self.x_v[:, i] = (self.x_v[:, i] - np.mean(self.x_v[:, i]))/(np.std(self.x_v[:, i]))\n",
    "\n",
    "            if(not np.any(self.x_t[:, i])):\n",
    "                self.x_t[:, i].fill(0)\n",
    "            else:\n",
    "                self.x_t[:, i] = (self.x_t[:, i] - np.mean(self.x_t[:, i]))/(np.std(self.x_t[:, i]))  \n",
    "        \n",
    "        self.x_v = np.insert(self.x_v, 0, 1, axis=1)\n",
    "        self.x_t = np.insert(self.x_t, 0, 1, axis=1)\n",
    "\n",
    "                \n",
    "    def gradient_update(self):\n",
    "        loss = self.loss()\n",
    "        # self.B = self.B - self.lr * self.loss()\n",
    "        self.B = self.B - self.lr * loss\n",
    "        return self.B, loss\n",
    "    \n",
    "    def loss(self):\n",
    "        #temp = np.sum(self.x_t*self.B, axis=1)\n",
    "        temp = np.dot(self.x_t, self.B)\n",
    "        temp = np.dot(temp, self.y_t.flatten())\n",
    "        if temp > 1:\n",
    "            temp = 0\n",
    "        else:\n",
    "            var = (temp - 1)**2\n",
    "            temp = np.log(1 + var)\n",
    "        '''\n",
    "        for index in range(0, len(temp)):\n",
    "            if temp[index] > 1:\n",
    "                temp[index] = 0\n",
    "            else:\n",
    "                var = (temp[index] - 1)**2\n",
    "                temp[index] = np.log(1 + var)\n",
    "        '''            \n",
    "        temp += self.s * LA.norm(self.B, 2)        \n",
    "        temp /= self.N \n",
    "        return temp\n",
    "        # 0            if x > 1\n",
    "        # ln(1+(x-1)^2) else\n",
    "    \n",
    "    def predict(self):\n",
    "        # print(self.B.shape)\n",
    "        # print(self.x_t.shape)\n",
    "        xB = np.matmul(self.x_t, self.B)\n",
    "        yPred = np.sign(xB)\n",
    "        # print(self.y_t.shape, yPred.shape)\n",
    "        trainAcc = 1- np.mean(yPred == self.y_t)\n",
    "        \n",
    "        xB = np.matmul(self.x_v, self.B)\n",
    "        yPred = np.sign(xB)\n",
    "        testAcc = 1- np.mean(yPred == self.y_v)\n",
    "        return trainAcc, testAcc\n",
    "    \n",
    "    def train(self, k):\n",
    "        mPrev = self.M\n",
    "        for i in range(0, self.N_iter):\n",
    "            if k == 30:\n",
    "                B, loss = self.gradient_update()\n",
    "                self.losses.append(loss)\n",
    "            else:\n",
    "                self.gradient_update()\n",
    "            temp = (self.N_iter - 2 * i)/(2 * i * self.u + self.N_iter)\n",
    "            temp = max(0., temp)\n",
    "            # mi = self.k + (self.M - self.k) * temp\n",
    "            mi = k + (self.M - k) * temp\n",
    "            if mi < mPrev:\n",
    "                # feature removal goes here\n",
    "                while np.count_nonzero(self.B) > mi:\n",
    "                    minimum = np.amin(self.B, where=np.where(self.B != 0))\n",
    "                    indices = np.where(self.B == minimum)\n",
    "                    for index in indices:\n",
    "                        self.B[index] = 0\n",
    "                        if np.count_nonzero(self.B) == mi:\n",
    "                            break    \n",
    "                mPrev = mi\n",
    "            print(\"Iteration: \", i, \"M_i: \", int(mi))\n",
    "            print('Non-zero count: ', np.count_nonzero(self.B))\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "    def print_features(self):\n",
    "        print(\"X_train Objs: \", self.x_t.shape[0], \"X_train Feats: \", self.x_t.shape[1])\n",
    "        print(\"Y_train Objs: \", self.y_t.shape[0])\n",
    "\n",
    "        print(\"\\nX_valid Objs: \", self.x_v.shape[0], \"X_valid Feats: \", self.x_v.shape[1])\n",
    "        print(\"Y_valid Objs: \", self.y_v.shape[0])\n",
    "\n",
    "                \n",
    "        #self.x_t, self.y_t, self.x_v, self.y_v = x_train, y_train, x_valid, y_valid \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select k = [10, 30, 100, 300] features\n",
    "# Plot the training loss vs iteration number k = 10\n",
    "# Report in Table the misclassification errors on the training and testing set for models obtained for all k\n",
    "# Plot the misclassification error on the training set and testing set vs k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = [10, 30, 100, 300, 500]\n",
    "trainErrors = []\n",
    "testErrors = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Madelon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_file = \"../data/MADELON/madelon_train.data\"\n",
    "y_train_file = \"../data/MADELON/madelon_train.labels\"\n",
    "\n",
    "x_valid_file = \"../data/MADELON/madelon_valid.data\"\n",
    "y_valid_file = \"../data/MADELON/madelon_valid.labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0 M_i:  501\n",
      "Non-zero count:  501\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "amin() got an unexpected keyword argument 'where'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-69c70ad9d60f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#model.print_features()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtrainAccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestAccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtrainErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtrainAccuracy\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-1880d08fff39>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;31m# feature removal goes here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                     \u001b[0mminimum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mB\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m                     \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mB\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mminimum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: amin() got an unexpected keyword argument 'where'"
     ]
    }
   ],
   "source": [
    "model = FSA(x_train_file, y_train_file, x_valid_file, y_valid_file)\n",
    "iterations = np.arange(0, model.N_iter)\n",
    "for k in K:\n",
    "    #model.print_features()\n",
    "    model.train(k)\n",
    "    trainAccuracy, testAccuracy = model.predict()\n",
    "    trainErrors.append(round((1-trainAccuracy) * 100), 2)\n",
    "    testErrors.append(round((1-testAccuracy) * 100), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xVals, model.losses, linestyle='-', marker='o', color='g')\n",
    "plt.grid(True)\n",
    "plt.xticks(xVals)\n",
    "plt.title('Training Loss vs Iteration Number k=30')\n",
    "plt.xlabel('Iteration Number (i)')\n",
    "plt.ylabel('Training Loss (L_i)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k, trainErrors, linestyle='-', marker='o', color='r', label='Train')\n",
    "plt.plot(k, testErrors, linestyle='-', marker='o', color='b', label='Test')\n",
    "plt.grid(True)\n",
    "plt.xticks(k)\n",
    "plt.title('Misclassification Error vs Number of Features')\n",
    "plt.xlabel('Number of Features (k)')\n",
    "plt.ylabel('Misclassification Error (%)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorTableMadelon = pd.DataFrame({\"Training Error (%)\":[0, 0, 0, 0, 0], \"Test Error (%)\":[0, 0, 0, 0, 0]}, index=K)\n",
    "errorTableMadelon.index.name = \"N Features\"\n",
    "for k, trainErr, testErr in zip(K, trainErrors, testErrors):\n",
    "    errorTableMadelon.loc[k, 'Training Error (%)'] = trainErr\n",
    "    errorTableMadelon.loc[k, 'Test Error (%)'] = testErr\n",
    "    \n",
    "errorTableMadelon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainErrors.clear()\n",
    "testErrors.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dexter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_file = \"../data/dexter/dexter_train.csv\"\n",
    "y_train_file = \"../data/dexter/dexter_train.labels\"\n",
    "\n",
    "x_valid_file = \"../data/dexter/dexter_valid.csv\"\n",
    "y_valid_file = \"../data/dexter/dexter_valid.labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FSA(x_train_file, y_train_file, x_valid_file, y_valid_file)\n",
    "model.print_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xVals, model.losses, linestyle='-', marker='o', color='g')\n",
    "plt.grid(True)\n",
    "plt.xticks(xVals)\n",
    "plt.title('Training Loss vs Iteration Number k=30')\n",
    "plt.xlabel('Iteration Number (i)')\n",
    "plt.ylabel('Training Loss (L_i)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k, trainErrors, linestyle='-', marker='o', color='r', label='Train')\n",
    "plt.plot(k, testErrors, linestyle='-', marker='o', color='b', label='Test')\n",
    "plt.grid(True)\n",
    "plt.xticks(k)\n",
    "plt.title('Misclassification Error vs Number of Features')\n",
    "plt.xlabel('Number of Features (k)')\n",
    "plt.ylabel('Misclassification Error (%)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorTableDexter = pd.DataFrame({\"Training Error (%)\":[0, 0, 0, 0, 0], \"Test Error (%)\":[0, 0, 0, 0, 0]}, index=K)\n",
    "errorTableDexter.index.name = \"N Features\"\n",
    "for k, trainErr, testErr in zip(K, trainErrors, testErrors):\n",
    "    errorTableDexter.loc[k, 'Training Error (%)'] = trainErr\n",
    "    errorTableDexter.loc[k, 'Test Error (%)'] = testErr\n",
    "    \n",
    "errorTableMadelon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainErrors.clear()\n",
    "testErrors.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gisette "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_file = \"../data/Gisette/gisette_train.data\"\n",
    "y_train_file = \"../data/Gisette/gisette_train.labels\"\n",
    "\n",
    "x_valid_file = \"../data/Gisette/gisette_valid.data\"\n",
    "y_valid_file = \"../data/Gisette/gisette_valid.labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FSA(x_train_file, y_train_file, x_valid_file, y_valid_file)\n",
    "model.print_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xVals, model.losses, linestyle='-', marker='o', color='g')\n",
    "plt.grid(True)\n",
    "plt.xticks(xVals)\n",
    "plt.title('Training Loss vs Iteration Number k=30')\n",
    "plt.xlabel('Iteration Number (i)')\n",
    "plt.ylabel('Training Loss (L_i)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k, trainErrors, linestyle='-', marker='o', color='r', label='Train')\n",
    "plt.plot(k, testErrors, linestyle='-', marker='o', color='b', label='Test')\n",
    "plt.grid(True)\n",
    "plt.xticks(k)\n",
    "plt.title('Misclassification Error vs Number of Features')\n",
    "plt.xlabel('Number of Features (k)')\n",
    "plt.ylabel('Misclassification Error (%)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorTableGisette = pd.DataFrame({\"Training Error (%)\":[0, 0, 0, 0, 0], \"Test Error (%)\":[0, 0, 0, 0, 0]}, index=K)\n",
    "errorTableGisette.index.name = \"N Features\"\n",
    "for k, trainErr, testErr in zip(K, trainErrors, testErrors):\n",
    "    errorTableGisette.loc[k, 'Training Error (%)'] = trainErr\n",
    "    errorTableGisette.loc[k, 'Test Error (%)'] = testErr\n",
    "    \n",
    "errorTableMadelon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commented Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Load Data:    \n",
    "    # x_valid = np.insert(x_valid, 0, 1, axis=1)\n",
    "    # x_train = np.insert(x_train, 0, 1, axis=1)\n",
    "\n",
    "    #y_valid = np.where(y_valid == -1, 0, y_valid)  \n",
    "    #y_train = np.where(y_train == -1, 0, y_train)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
