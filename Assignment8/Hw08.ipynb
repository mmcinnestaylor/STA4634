{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import linalg as LA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogitBoost:\n",
    "    def __init__(self, xt, yt, xv, yv, k):\n",
    "        self.load_data(xt, yt, xv, yv)\n",
    "        \n",
    "        self.N_iter = k\n",
    "        \n",
    "        self.M = self.x_t.shape[1]\n",
    "        self.N = self.x_t.shape[0]\n",
    "        self.B = np.zeros(self.M)\n",
    "        \n",
    "        self.losses = []\n",
    "    \n",
    "    \n",
    "    def load_data(self, x_train_file, y_train_file, x_valid_file, y_valid_file):\n",
    "        if \"dexter\" in x_train_file:\n",
    "            self.x_t = np.loadtxt(x_train_file, delimiter=',')\n",
    "            self.x_v = np.loadtxt(x_valid_file, delimiter=',')\n",
    "        else:\n",
    "            self.x_t = np.loadtxt(x_train_file)\n",
    "            self.x_v = np.loadtxt(x_valid_file)\n",
    "        \n",
    "        self.y_t = np.loadtxt(y_train_file) \n",
    "        self.y_v = np.loadtxt(y_valid_file) \n",
    "        \n",
    "        self.y_t = self.y_t.flatten()\n",
    "        self.y_v = self.y_v.flatten()\n",
    "        \n",
    "        self.x_t = np.insert(self.x_t, 0, 1., axis=1)\n",
    "        self.x_v = np.insert(self.x_v, 0, 1., axis=1)\n",
    "        \n",
    "        self.N = self.x_t.shape[0]   # Rows\n",
    "        self.M = self.x_t.shape[1]   # Columns         \n",
    "\n",
    "                \n",
    "    def gradient_update(self):\n",
    "        \n",
    "        return 0\n",
    "    \n",
    "    def loss(self, H_j):\n",
    "        t1 = 1 + np.exp((-2 * self.y_t - 1) *H_j)\n",
    "        loss = np.sum(np.log(t1+0.01))\n",
    "        return loss\n",
    "\n",
    "    def predict(self):\n",
    "        xB = np.matmul(self.x_t, self.B)\n",
    "        yPred = np.sign(xB)\n",
    "        trainAcc = 1- np.mean(yPred == self.y_t.flatten())\n",
    "        \n",
    "        xB = np.matmul(self.x_v, self.B)\n",
    "        yPred = np.sign(xB)\n",
    "        testAcc = 1 - np.mean(yPred == self.y_v.flatten())\n",
    "        return trainAcc, testAcc\n",
    "    \n",
    "    def train(self):\n",
    "        self.losses = np.zeros(self.N_iter)\n",
    "        for i in range(self.N_iter):\n",
    "            # Calculate H(x)\n",
    "            H = np.matmul(self.x_t, self.B)\n",
    "            \n",
    "            # Calculate the p,w,z to use for 1D weak classifiers\n",
    "            p = (1)/(1 + np.exp(-2*H))\n",
    "            w = (p)*(1 - p)\n",
    "            z = (0.5*(self.y_t + 1) - p)/(w) \n",
    "            \n",
    "            coef = np.zeros((2, self.M - 1))\n",
    "            newloss = np.zeros((self.M - 1, 1))\n",
    "            \n",
    "            for j in range(self.M-1):\n",
    "                # Get jth feature, + 1 is to avoid Bias/1's added into data in first column\n",
    "                x_j = self.x_t[:,j + 1]\n",
    "                \n",
    "                # Weighted Least Squares\n",
    "                t1 = np.sum(w)\n",
    "                t2 = np.sum(w * x_j)\n",
    "                t3 = np.sum(w * (x_j ** 2))\n",
    "                t4 = np.sum(w * z)\n",
    "                t5 = np.sum(w * x_j * z)\n",
    "\n",
    "                t6 = np.array([t3*t4-t2*t5, t1*t5 - t2*t4])\n",
    "                t7 = t1 * t3 - (t2**2)\n",
    "                \n",
    "                # Check if 0, to avoid divide by zero later on\n",
    "                if t7 == 0:\n",
    "                    B_j = np.array([t4/t1, 0])\n",
    "                else:\n",
    "                    B_j = ((1)/(t7)) * t6 \n",
    "                \n",
    "                H_j = H + 0.5*(B_j[0] + B_j[1] * x_j)\n",
    "                \n",
    "                # Calculate the loss for this feature\n",
    "                # Store the loss inside newloss, to choose the min loss later on\n",
    "                newloss[j] = self.loss(H_j)\n",
    "                \n",
    "                # Update coef for updating the B matrix\n",
    "                coef[:, j] = B_j\n",
    "           \n",
    "            # Choose the iteration/regression on the feature that had the min loss\n",
    "            j_hat = np.argmin(newloss)\n",
    "            \n",
    "            # Update B matrix\n",
    "            self.B[0] = self.B[0] +  0.5 * coef[0, j_hat]  \n",
    "            self.B[j_hat + 1] = self.B[j_hat + 1] +  0.5 * coef[1, j_hat]\n",
    "            \n",
    "            # Store min loss of 1D classifiers for this iteration\n",
    "            self.losses[i] = newloss[j_hat]\n",
    "            \n",
    "            # Print out the loss for this itertation of this k value\n",
    "            print(\"\\rk: \", str(self.N_iter), \"  Iteration: \", str(i), \"  Loss: \", round(self.losses[i], 2), sep='', end='', flush=True)\n",
    "        print(\"\")\n",
    "    \n",
    "    def print_features(self):\n",
    "        print(\"X_train Objs: \", self.x_t.shape[0], \"X_train Feats: \", self.x_t.shape[1])\n",
    "        print(\"Y_train Objs: \", self.y_t.shape[0])\n",
    "\n",
    "        print(\"\\nX_valid Objs: \", self.x_v.shape[0], \"X_valid Feats: \", self.x_v.shape[1])\n",
    "        print(\"Y_valid Objs: \", self.y_v.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLosses(xVals, losses):\n",
    "    plt.plot(xVals[1:], losses[1:], linestyle='-', marker='o', color='g')\n",
    "    plt.grid(True)\n",
    "    plt.title('Training Loss vs Boosted Iterations k=500')\n",
    "    plt.xlabel('Iteration Number (i)')\n",
    "    plt.ylabel('Training Loss (L_i)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotErrors(K, trainErrors, testErrors):\n",
    "    plt.plot(K, trainErrors, linestyle='-', marker='o', color='r', label='Train')\n",
    "    plt.plot(K, testErrors, linestyle='-', marker='o', color='b', label='Test')\n",
    "    plt.grid(True)\n",
    "    plt.title('Misclassification Error vs Number of Boosted Iterations')\n",
    "    plt.xlabel('Number of Boosted Iterations (k)')\n",
    "    plt.ylabel('Misclassification Error (%)')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genErrorTable(K, trainErrors, testErrors):\n",
    "    errorTable = pd.DataFrame({\"Training Error (%)\":[0, 0, 0, 0, 0], \"Test Error (%)\":[0, 0, 0, 0, 0]}, index=K)\n",
    "    errorTable.index.name = \"Iterations\"\n",
    "    for k, trainErr, testErr in zip(K, trainErrors, testErrors):\n",
    "        errorTable.loc[k, 'Training Error (%)'] = trainErr\n",
    "        errorTable.loc[k, 'Test Error (%)'] = testErr\n",
    "\n",
    "    return errorTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runModel(K):\n",
    "    trainErrors = []\n",
    "    testErrors = []\n",
    "    \n",
    "    for k in K:\n",
    "        model = LogitBoost(x_train_file, y_train_file, x_valid_file, y_valid_file, k)\n",
    "        model.train()\n",
    "        if k == 500:\n",
    "            losses = model.losses\n",
    "        trainAccuracy, testAccuracy = model.predict()\n",
    "        #print(trainAccuracy, testAccuracy)\n",
    "        trainErrors.append(round((trainAccuracy) * 100, 2))\n",
    "        testErrors.append(round((testAccuracy) * 100, 2))\n",
    "    print(\"Train Errors: \", trainErrors)\n",
    "    print(\"Test Errors: \", testErrors)\n",
    "    \n",
    "    return losses, trainErrors, testErrors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = [10, 30, 100, 300, 500]\n",
    "xVals = xVals = np.arange(1, 501)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Madelon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_file = \"../data/MADELON/madelon_train.data\"\n",
    "y_train_file = \"../data/MADELON/madelon_train.labels\"\n",
    "\n",
    "x_valid_file = \"../data/MADELON/madelon_valid.data\"\n",
    "y_valid_file = \"../data/MADELON/madelon_valid.labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 10  Iteration: 9  Loss: 1326.47\n",
      "k: 30  Iteration: 29  Loss: 1284.53\n",
      "k: 100  Iteration: 67  Loss: 1229.85"
     ]
    }
   ],
   "source": [
    "losses, trainErrors, testErrors = runModel(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotLosses(xVals, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotErrors(K, trainErrors, testErrors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = genErrorTable(K, trainErrors, testErrors)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dexter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_file = \"../data/dexter/dexter_train.csv\"\n",
    "y_train_file = \"../data/dexter/dexter_train.labels\"\n",
    "\n",
    "x_valid_file = \"../data/dexter/dexter_valid.csv\"\n",
    "y_valid_file = \"../data/dexter/dexter_valid.labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, trainErrors, testErrors = runModel(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotLosses(xVals, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotErrors(K, trainErrors, testErrors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = genErrorTable(K, trainErrors, testErrors)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gisette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_file = \"../data/Gisette/gisette_train.data\"\n",
    "y_train_file = \"../data/Gisette/gisette_train.labels\"\n",
    "\n",
    "x_valid_file = \"../data/Gisette/gisette_valid.data\"\n",
    "y_valid_file = \"../data/Gisette/gisette_valid.labels\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, trainErrors, testErrors = runModel(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotLosses(xVals, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotErrors(K, trainErrors, testErrors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = genErrorTable(K, trainErrors, testErrors)\n",
    "table"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
