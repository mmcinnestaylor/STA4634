{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAMES: Timothy Barao, Marlan McInnes-Taylor\n",
    "# FSUIDS: tjb13b, mm05f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logiboost:\n",
    "    def __init__(self, xt, yt, xv, yv):\n",
    "        self.load_data(xt, yt, xv, yv)\n",
    "        self.B_all = np.zeros(self.M)\n",
    "     \n",
    "    def load_data(self, x_train_file, y_train_file, x_valid_file, y_valid_file):\n",
    "        if \"dexter\" in x_train_file:\n",
    "            self.x_t = np.loadtxt(x_train_file, delimiter=',')\n",
    "            self.x_v = np.loadtxt(x_valid_file, delimiter=',')\n",
    "        else:\n",
    "            self.x_t = np.loadtxt(x_train_file)\n",
    "            self.x_v = np.loadtxt(x_valid_file)\n",
    "        \n",
    "        self.y_t = np.loadtxt(y_train_file) \n",
    "        self.y_v = np.loadtxt(y_valid_file) \n",
    "        \n",
    "        self.y_t = self.y_t.flatten()\n",
    "        self.y_v = self.y_v.flatten()\n",
    "        \n",
    "        self.x_t = np.insert(self.x_t, 0, 1., axis=1)\n",
    "        self.x_v = np.insert(self.x_v, 0, 1., axis=1)\n",
    "        \n",
    "        self.N = self.x_t.shape[0]   # Rows\n",
    "        self.M = self.x_t.shape[1]   # Columns         \n",
    "    \n",
    "    def WLS(self, w, z, j):\n",
    "        \n",
    "        x_j = self.x_t[:, j + 1]\n",
    "\n",
    "        a = np.sum(w)\n",
    "        b = np.sum(w * x_j)\n",
    "        c = np.sum(w * (x_j ** 2))\n",
    "        d = np.sum(w * z)\n",
    "        e = np.sum(w * x_j * z)\n",
    "\n",
    "        f = np.array([c*d-b*e, a*e - b*d])\n",
    "        g = a * c - (b**2)\n",
    "        if g == 0:\n",
    "            B_j = np.array([d/a, 0])\n",
    "        else:\n",
    "            B_j = ((1)/(g)) * f  \n",
    "       \n",
    "        return B_j\n",
    "            \n",
    "    def plot(self, k):\n",
    "        plt.plot(np.arange(0, k), self.losses, linestyle='-', marker='o', color='g')\n",
    "        plt.grid(True)\n",
    "        plt.title('Training Loss vs Iteration Number k=30')\n",
    "        plt.xlabel('Iteration Number (i)')\n",
    "        plt.ylabel('Training Loss (L_i)')\n",
    "        plt.show()\n",
    "    \n",
    "    def train(self, k):\n",
    "        self.losses = np.zeros(k)\n",
    "        for i in range(k):\n",
    "            H = np.matmul(self.x_t,self.B_all) #???\n",
    "               \n",
    "            p = (1)/(1 + np.exp(-2 * H))\n",
    "            w = p * (1 - p)\n",
    "            z = (0.5*(self.y_t + 1) - p)/(w)     \n",
    "            \n",
    "            coef = np.zeros((2, self.M - 1))\n",
    "            newloss = np.zeros((self.M - 1, 1))\n",
    "            \n",
    "            a = np.sum(w)\n",
    "            b = np.dot(w, self.x_t)\n",
    "            c = np.dot(w, (self.x_t ** 2))\n",
    "            d = np.dot(w, z)\n",
    "            e = np.dot(np.dot(w, self.x_t), z)\n",
    "                       \n",
    "                       \n",
    "            \n",
    "            for j in range(self.M-1):        \n",
    "                x_j = self.x_t[:, j + 1]\n",
    "\n",
    "                a = np.sum(w)\n",
    "                b = np.sum(w * x_j)\n",
    "                c = np.sum(w * (x_j ** 2))\n",
    "                d = np.sum(w * z)\n",
    "                e = np.sum(w * x_j * z)\n",
    "\n",
    "                f = np.array([c*d-b*e, a*e - b*d])\n",
    "                g = a * c - (b**2)\n",
    "                if g == 0:\n",
    "                    B_j = np.array([d/a, 0])\n",
    "                else:\n",
    "                    B_j = ((1)/(g)) * f  \n",
    "                \n",
    "                H_j = H + 0.5*(B_j[0] + B_j[1] * x_j)\n",
    "                                                      \n",
    "                loss = np.sum(np.log(1 + np.exp((-2 * self.y_t - 1) *H_j)))\n",
    "                \n",
    "                coef[:, j] = B_j\n",
    "                newloss[j] = loss\n",
    "           \n",
    "            j_hat = np.argmin(newloss)\n",
    "            \n",
    "            self.B_all[0] = self.B_all[0] +  0.5 * coef[0, j_hat]  \n",
    "            self.B_all[j_hat + 1] = self.B_all[j_hat + 1] +  0.5 * coef[1, j_hat]\n",
    "            self.losses[i] = newloss[j_hat]+0.00001\n",
    "            print(\"\\rk: \", k, \"Iteration: \", i, \"Loss: \", newloss[j_hat], end=\"\", flush=True)\n",
    "            \n",
    "            \n",
    "        y_train_p = np.sign(np.matmul(self.x_t,self.B_all))\n",
    "        y_test_p = np.sign(np.matmul(self.x_v,self.B_all))\n",
    "        \n",
    "        tr_err = 1 - np.mean(np.equal(y_train_p, self.y_t))\n",
    "        v_err = 1 - np.mean(np.equal(y_test_p, self.y_v))\n",
    "        \n",
    "        print(\"\\nTraining Error: \", tr_err)\n",
    "        print(\"Testing Error: \", v_err)\n",
    "        \n",
    "    def print_features(self):\n",
    "        print(\"\\n=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\")\n",
    "        print(\"X_train Objs: \", self.x_t.shape[0], \"X_train Feats: \", self.x_t.shape[1])\n",
    "        print(\"Y_train Objs: \", self.y_t.shape[0])\n",
    "        print(\"\\nX_valid Objs: \", self.x_v.shape[0], \"X_valid Feats: \", self.x_v.shape[1])\n",
    "        print(\"Y_valid Objs: \", self.y_v.shape[0])\n",
    "        print(\"=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K = [10, 30, 100, 300, 500]\n",
    "K = [300]\n",
    "trainErrors = []\n",
    "testErrors = []\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Madelon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_file = \"../data/MADELON/madelon_train.data\"\n",
    "y_train_file = \"../data/MADELON/madelon_train.labels\"\n",
    "\n",
    "x_valid_file = \"../data/MADELON/madelon_valid.data\"\n",
    "y_valid_file = \"../data/MADELON/madelon_valid.labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (501,) and (2000,) not aligned: 501 (dim 0) != 2000 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-09c2ea1ca8ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogiboost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_valid_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-bfc9a0547aa1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_t\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (501,) and (2000,) not aligned: 501 (dim 0) != 2000 (dim 0)"
     ]
    }
   ],
   "source": [
    "for k in K:\n",
    "    model = Logiboost(x_train_file, y_train_file, x_valid_file, y_valid_file)\n",
    "    model.train(k)\n",
    "    model.plot(k)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dexter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_file = \"../data/dexter/dexter_train.csv\"\n",
    "y_train_file = \"../data/dexter/dexter_train.labels\"\n",
    "\n",
    "x_valid_file = \"../data/dexter/dexter_valid.csv\"\n",
    "y_valid_file = \"../data/dexter/dexter_valid.labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in K:\n",
    "    model = Logiboost(x_train_file, y_train_file, x_valid_file, y_valid_file)\n",
    "    model.train(k)\n",
    "    model.plot(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gisette "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_file = \"../data/Gisette/gisette_train.data\"\n",
    "y_train_file = \"../data/Gisette/gisette_train.labels\"\n",
    "\n",
    "x_valid_file = \"../data/Gisette/gisette_valid.data\"\n",
    "y_valid_file = \"../data/Gisette/gisette_valid.labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in K:\n",
    "    model = Logiboost(x_train_file, y_train_file, x_valid_file, y_valid_file)\n",
    "    model.train(k)\n",
    "    model.plot(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h(x, O_k) = a * x_j + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logiboost:\n",
    "    def __init__(self, xt, yt, xv, yv):\n",
    "        self.load_data(xt, yt, xv, yv)\n",
    "        self.B_all = np.zeros(self.M)\n",
    "     \n",
    "    def load_data(self, x_train_file, y_train_file, x_valid_file, y_valid_file):\n",
    "        if \"dexter\" in x_train_file:\n",
    "            self.x_t = np.loadtxt(x_train_file, delimiter=',')\n",
    "            self.x_v = np.loadtxt(x_valid_file, delimiter=',')\n",
    "        else:\n",
    "            self.x_t = np.loadtxt(x_train_file)\n",
    "            self.x_v = np.loadtxt(x_valid_file)\n",
    "        \n",
    "        self.y_t = np.loadtxt(y_train_file) \n",
    "        self.y_v = np.loadtxt(y_valid_file) \n",
    "        \n",
    "        self.y_t = self.y_t.flatten()\n",
    "        self.y_v = self.y_v.flatten()\n",
    "        \n",
    "        self.x_t = np.insert(self.x_t, 0, 1., axis=1)\n",
    "        self.x_v = np.insert(self.x_v, 0, 1., axis=1)\n",
    "        \n",
    "        self.N = self.x_t.shape[0]   # Rows\n",
    "        self.M = self.x_t.shape[1]   # Columns         \n",
    " \n",
    "        #self.print_features()\n",
    "              \n",
    "    #def gradient_update(self):  \n",
    "\n",
    "    \n",
    "    #def loss(self):\n",
    "\n",
    "\n",
    "    #def predict(self):\n",
    "    \n",
    "    def WLS(self, w, z, j):\n",
    "        \n",
    "        x_j = self.x_t[:, j + 1]\n",
    "\n",
    "        a = np.sum(w)\n",
    "        b = np.sum(w * x_j)\n",
    "        c = np.sum(w * (x_j ** 2))\n",
    "        d = np.sum(w * z)\n",
    "        e = np.sum(w * x_j * z)\n",
    "\n",
    "        f = np.array([c*d-b*e, a*e - b*d])\n",
    "        g = a * c - (b**2)\n",
    "        if g == 0:\n",
    "            B_j = np.array([d/a, 0])\n",
    "        else:\n",
    "            B_j = ((1)/(g)) * f  \n",
    "       \n",
    "        return B_j\n",
    "            \n",
    "    def plot(self, k):\n",
    "        plt.plot(np.arange(0, k), self.losses, linestyle='-', marker='o', color='g')\n",
    "        plt.grid(True)\n",
    "        plt.title('Training Loss vs Iteration Number k=30')\n",
    "        plt.xlabel('Iteration Number (i)')\n",
    "        plt.ylabel('Training Loss (L_i)')\n",
    "        plt.show()\n",
    "    \n",
    "    def train(self, k):\n",
    "        self.losses = np.zeros(k)\n",
    "        for i in range(k):\n",
    "            H = np.matmul(self.x_t,self.B_all) #???\n",
    "               \n",
    "            p = (1)/(1 + np.exp(-2 * H))\n",
    "            w = p * (1 - p)\n",
    "            z = (0.5*(self.y_t + 1) - p)/(w)     \n",
    "            \n",
    "            coef = np.zeros((2, self.M - 1))\n",
    "            newloss = np.zeros((self.M - 1, 1))\n",
    "            \n",
    "            for j in range(self.M-1):\n",
    "                B_j = self.WLS(w, z, j)\n",
    "                \n",
    "                H_j = H + 0.5*(B_j[0] + B_j[1] * x_j)\n",
    "                                                      #predicted values? \n",
    "                loss = np.sum(np.log(1 + np.exp((-2 * self.y_t - 1) *H_j)))\n",
    "                \n",
    "                coef[:, j] = B_j\n",
    "                newloss[j] = loss\n",
    "           \n",
    "            j_hat = np.argmin(newloss)\n",
    "            \n",
    "            self.B_all[0] = self.B_all[0] +  0.5 * coef[0, j_hat]  \n",
    "            self.B_all[j_hat + 1] = self.B_all[j_hat + 1] +  0.5 * coef[1, j_hat]\n",
    "            self.losses[i] = newloss[j_hat]\n",
    "            print(\"\\rk: \", k, \"Iteration: \", i, \"Loss: \", newloss[j_hat], end=\"\", flush=True)\n",
    "            \n",
    "            \n",
    "        y_train_p = np.sign(np.matmul(self.x_t,self.B_all))\n",
    "        y_test_p = np.sign(np.matmul(self.x_v,self.B_all))\n",
    "        \n",
    "        tr_err = 1 - np.mean(np.equal(y_train_p, self.y_t))\n",
    "        v_err = 1 - np.mean(np.equal(y_test_p, self.y_v))\n",
    "        \n",
    "        print(\"\\nTraining Error: \", tr_err)\n",
    "        print(\"Testing Error: \", v_err)\n",
    "        \n",
    "    def print_features(self):\n",
    "        print(\"\\n=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\")\n",
    "        print(\"X_train Objs: \", self.x_t.shape[0], \"X_train Feats: \", self.x_t.shape[1])\n",
    "        print(\"Y_train Objs: \", self.y_t.shape[0])\n",
    "        print(\"\\nX_valid Objs: \", self.x_v.shape[0], \"X_valid Feats: \", self.x_v.shape[1])\n",
    "        print(\"Y_valid Objs: \", self.y_v.shape[0])\n",
    "        print(\"=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logiboost:\n",
    "    def __init__(self, xt, yt, xv, yv):\n",
    "        self.load_data(xt, yt, xv, yv)\n",
    "        self.B_all = np.zeros(self.M)\n",
    "     \n",
    "    def load_data(self, x_train_file, y_train_file, x_valid_file, y_valid_file):\n",
    "        if \"dexter\" in x_train_file:\n",
    "            self.x_t = np.loadtxt(x_train_file, delimiter=',')\n",
    "            self.x_v = np.loadtxt(x_valid_file, delimiter=',')\n",
    "        else:\n",
    "            self.x_t = np.loadtxt(x_train_file)\n",
    "            self.x_v = np.loadtxt(x_valid_file)\n",
    "        \n",
    "        self.y_t = np.loadtxt(y_train_file) \n",
    "        self.y_v = np.loadtxt(y_valid_file) \n",
    "        \n",
    "        self.y_t = self.y_t.flatten()\n",
    "        self.y_v = self.y_v.flatten()\n",
    "        \n",
    "        self.x_t = np.insert(self.x_t, 0, 1., axis=1)\n",
    "        self.x_v = np.insert(self.x_v, 0, 1., axis=1)\n",
    "        \n",
    "        self.N = self.x_t.shape[0]   # Rows\n",
    "        self.M = self.x_t.shape[1]   # Columns         \n",
    " \n",
    "        #self.print_features()\n",
    "              \n",
    "    #def gradient_update(self):  \n",
    "\n",
    "    \n",
    "    #def loss(self):\n",
    "\n",
    "\n",
    "    #def predict(self):\n",
    "    \n",
    "    def WLS(self, w, z, j, x_j):\n",
    "        a = np.sum(w)\n",
    "        b = np.sum(w * x_j)\n",
    "        c = np.sum(w * (x_j ** 2))\n",
    "        d = np.sum(w * z)\n",
    "        e = np.sum(w * x_j * z)\n",
    "\n",
    "        f = np.array([c*d-b*e, a*e - b*d])\n",
    "        g = a * c - (b**2)\n",
    "        if g == 0:\n",
    "            B_j = np.array([d/a, 0])\n",
    "        else:\n",
    "            B_j = ((1)/(g)) * f  \n",
    "       \n",
    "        return B_j\n",
    "            \n",
    "    def plot(self, k):\n",
    "        plt.plot(np.arange(0, k), self.losses, linestyle='-', marker='o', color='g')\n",
    "        plt.grid(True)\n",
    "        plt.title('Training Loss vs Iteration Number k=30')\n",
    "        plt.xlabel('Iteration Number (i)')\n",
    "        plt.ylabel('Training Loss (L_i)')\n",
    "        plt.show()\n",
    "    \n",
    "    def train(self, k):\n",
    "        self.losses = np.zeros(k)\n",
    "        #H = np.zeros(self.M+1)\n",
    "        for i in range(k):\n",
    "            H = np.matmul(self.x_t, self.B_all)\n",
    "            #H = np.sign(H)  #may not be needed\n",
    "            \n",
    "            p = np.exp(H)/np.exp(H) + np.exp(-H)\n",
    "            w = (p)*(1 - p)\n",
    "            z = (self.y_t - p)/(p)*(1-p)\n",
    "            \n",
    "            print(\"H shape: \", H.shape)\n",
    "            print(\"p shape: \", p.shape)\n",
    "            print(\"w shape: \", w.shape)\n",
    "            print(\"z shape: \", z.shape)\n",
    "            \n",
    "            for j in range(self.M+1):\n",
    "                x_j = self.x_t[:j+1]\n",
    "                \n",
    "                \n",
    "            #H_j = np.argmin(H)\n",
    "            #loss = np.sum(np.log(1 + np.exp((-2 * self.y_t - 1) *H[H_j])))\n",
    "            #self.losses[i] = loss\n",
    "            \n",
    "            #print(\"H shape: \", H.shape)\n",
    "            #print(\"p shape: \", p.shape)\n",
    "            #print(\"w shape: \", w.shape)\n",
    "            #print(\"z shape: \", z.shape)\n",
    "            \n",
    "            #for j in range(self.M-1):\n",
    "            #self.B_all = self.B_all + 0.5 * H[H_j]\n",
    "            #print(\"\\rk: \", k, \"Iteration: \", i, \"Loss: \", loss, end=\"\", flush=True)\n",
    "            \n",
    "            \n",
    "        y_train_p = np.sign(np.matmul(self.x_t,self.B_all))\n",
    "        y_test_p = np.sign(np.matmul(self.x_v,self.B_all))\n",
    "        \n",
    "        tr_err = 1 - np.mean(np.equal(y_train_p, self.y_t))\n",
    "        v_err = 1 - np.mean(np.equal(y_test_p, self.y_v))\n",
    "        \n",
    "        print(\"\\nTraining Error: \", tr_err)\n",
    "        print(\"Testing Error: \", v_err)\n",
    "        \n",
    "    def print_features(self):\n",
    "        print(\"\\n=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\")\n",
    "        print(\"X_train Objs: \", self.x_t.shape[0], \"X_train Feats: \", self.x_t.shape[1])\n",
    "        print(\"Y_train Objs: \", self.y_t.shape[0])\n",
    "        print(\"\\nX_valid Objs: \", self.x_v.shape[0], \"X_valid Feats: \", self.x_v.shape[1])\n",
    "        print(\"Y_valid Objs: \", self.y_v.shape[0])\n",
    "        print(\"=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
