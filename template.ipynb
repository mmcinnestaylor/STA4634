{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogitBoost:\n",
    "    def __init__(self, xt, yt, xv, yv, k):\n",
    "        self.load_data(xt, yt, xv, yv)\n",
    "        \n",
    "        self.N_iter = k\n",
    "        # self.lr = 0.0001 \n",
    "\n",
    " \n",
    "        self.M = self.x_t.shape[1]\n",
    "        self.N = self.x_t.shape[0]\n",
    "        self.B = np.zeros(self.M)\n",
    "        \n",
    "        self.losses = []\n",
    "    \n",
    "    \n",
    "    def load_data(self, x_train_file, y_train_file, x_valid_file, y_valid_file):\n",
    "        with open(x_train_file) as file:\n",
    "            \n",
    "            if \"dexter\" in x_train_file:\n",
    "                self.x_t = pd.read_csv(file, delim_whitespace=False, header=None)\n",
    "            else:    \n",
    "                self.x_t = pd.read_csv(file, delim_whitespace=True, header=None)\n",
    "            self.x_t = self.x_t.to_numpy(dtype=np.float64)\n",
    "\n",
    "        with open(y_train_file) as file:\n",
    "            self.y_t = pd.read_csv(file, header=None)\n",
    "            self.y_t = self.y_t.to_numpy(dtype=np.float64)\n",
    "\n",
    "        with open(x_valid_file) as file:\n",
    "            \n",
    "            if \"dexter\" in x_valid_file:\n",
    "                self.x_v = pd.read_csv(file, delim_whitespace=False, header=None)\n",
    "            else:    \n",
    "                self.x_v = pd.read_csv(file, delim_whitespace=True, header=None)\n",
    "            self.x_v = self.x_v.to_numpy(dtype=np.float64)\n",
    "            \n",
    "        with open(y_valid_file) as file:\n",
    "            self.y_v = pd.read_csv(file, header=None)\n",
    "            self.y_v = self.y_v.to_numpy(dtype=np.float64)\n",
    "\n",
    "        self.N = self.x_t.shape[0]   # Rows\n",
    "        self.M = self.x_t.shape[1]   # Columns \n",
    "\n",
    "        # Standardize data\n",
    "        for i in range(0, self.M):\n",
    "            if (not np.any(self.x_v[:, i])):\n",
    "                self.x_v[:, i].fill(0)\n",
    "            else:  \n",
    "                self.x_v[:, i] = (self.x_v[:, i] - np.mean(self.x_v[:, i]))/(np.std(self.x_v[:, i]))\n",
    "\n",
    "            if(not np.any(self.x_t[:, i])):\n",
    "                self.x_t[:, i].fill(0)\n",
    "            else:\n",
    "                self.x_t[:, i] = (self.x_t[:, i] - np.mean(self.x_t[:, i]))/(np.std(self.x_t[:, i]))  \n",
    "        \n",
    "        self.x_v = np.insert(self.x_v, 0, 1, axis=1)\n",
    "        self.x_t = np.insert(self.x_t, 0, 1, axis=1)\n",
    "\n",
    "                \n",
    "    def gradient_update(self):\n",
    "        loss = self.loss()\n",
    "        self.B = self.B - self.lr * loss\n",
    "\n",
    "        \n",
    "        return self.B, LA.norm(loss)\n",
    "    \n",
    "    def loss(self):\n",
    "    \n",
    "        Bx=np.sum(self.x_t*self.B, axis=1)\n",
    "        yBx=np.sum(Bx*self.y_t.flatten())\n",
    "        \n",
    "        temp=2.*(yBx-1.)/(1.+(yBx-1.)*(yBx-1.))\n",
    "        temp=temp*self.y_t.flatten()\n",
    "        temp[yBx>1.]=0.\n",
    "        \n",
    "        grad=np.sum((self.x_t).T*temp, axis=1)+2.*self.s*self.B\n",
    "        return grad\n",
    "\n",
    "    def predict(self):\n",
    "        xB = np.matmul(self.x_t, self.B)\n",
    "        yPred = np.sign(xB)\n",
    "        trainAcc = 1- np.mean(yPred == self.y_t.flatten())\n",
    "        \n",
    "        xB = np.matmul(self.x_v, self.B)\n",
    "        yPred = np.sign(xB)\n",
    "        testAcc = 1 - np.mean(yPred == self.y_v.flatten())\n",
    "        return trainAcc, testAcc\n",
    "    \n",
    "    def train(self):\n",
    "        mPrev = self.M\n",
    "        for i in range(0, self.N_iter):\n",
    "            if k == 30:\n",
    "                B, loss = self.gradient_update()\n",
    "                self.losses.append(loss)\n",
    "            else:\n",
    "                self.gradient_update()\n",
    "            \n",
    "            temp = (self.N_iter - 2 * i)/(2 * i * self.u + self.N_iter)\n",
    "            temp = max(0., temp)\n",
    "            mi = k + (self.M - k) * temp\n",
    "            mi = int(mi)\n",
    "            \n",
    "            if mi < mPrev:\n",
    "                indc = np.absolute(self.B)\n",
    "                sort = np.argsort(indc)\n",
    "                sort = sort[-mi:]\n",
    "                self.B=self.B[sort]\n",
    "                self.x_t=(self.x_t.T[sort]).T\n",
    "                self.x_v=(self.x_v.T[sort]).T\n",
    "                mPrev = mi\n",
    "                \n",
    "            #print(\"Iteration: \", i, \"M_i: \", int(mi))\n",
    "            #print('Non-zero count: ', np.count_nonzero(self.B))\n",
    "            \n",
    "        return 0\n",
    "    \n",
    "    \n",
    "    def print_features(self):\n",
    "        print(\"X_train Objs: \", self.x_t.shape[0], \"X_train Feats: \", self.x_t.shape[1])\n",
    "        print(\"Y_train Objs: \", self.y_t.shape[0])\n",
    "\n",
    "        print(\"\\nX_valid Objs: \", self.x_v.shape[0], \"X_valid Feats: \", self.x_v.shape[1])\n",
    "        print(\"Y_valid Objs: \", self.y_v.shape[0])\n",
    "\n",
    "                \n",
    "        #self.x_t, self.y_t, self.x_v, self.y_v = x_train, y_train, x_valid, y_valid \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLosses(xVals, losses):\n",
    "    plt.plot(xVals[1:], losses[1:], linestyle='-', marker='o', color='g')\n",
    "    plt.grid(True)\n",
    "    plt.title('Training Loss vs Boosted Iterations k=500')\n",
    "    plt.xlabel('Iteration Number (i)')\n",
    "    plt.ylabel('Training Loss (L_i)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotErrors(K, trainErrors, testErrors):\n",
    "    plt.plot(K, trainErrors, linestyle='-', marker='o', color='r', label='Train')\n",
    "    plt.plot(K, testErrors, linestyle='-', marker='o', color='b', label='Test')\n",
    "    plt.grid(True)\n",
    "    plt.title('Misclassification Error vs Number of Boosted Iterations')\n",
    "    plt.xlabel('Number of Boosted Iterations (k)')\n",
    "    plt.ylabel('Misclassification Error (%)')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genErrorTable(K, trainErrors, testErrors):\n",
    "    errorTable = pd.DataFrame({\"Training Error (%)\":[0, 0, 0, 0, 0], \"Test Error (%)\":[0, 0, 0, 0, 0]}, index=K)\n",
    "    errorTable.index.name = \"Iterations\"\n",
    "    for k, trainErr, testErr in zip(K, trainErrors, testErrors):\n",
    "        errorTable.loc[k, 'Training Error (%)'] = trainErr\n",
    "        errorTable.loc[k, 'Test Error (%)'] = testErr\n",
    "\n",
    "    errorTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runModel(K):\n",
    "    trainErrors = []\n",
    "    testErrors = []\n",
    "    \n",
    "    for k in K:\n",
    "        model = LogitBoost(x_train_file, y_train_file, x_valid_file, y_valid_file, k)\n",
    "        model.train()\n",
    "        if k == 500:\n",
    "            losses = model.losses\n",
    "        trainAccuracy, testAccuracy = model.predict()\n",
    "        #print(trainAccuracy, testAccuracy)\n",
    "        trainErrors.append(round((trainAccuracy) * 100, 2))\n",
    "        testErrors.append(round((testAccuracy) * 100, 2))\n",
    "    print(\"Train Errors: \", trainErrors)\n",
    "    print(\"Test Errors: \", testErrors)\n",
    "    \n",
    "    return losses, trainErrors, testErrors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = [10, 30, 100, 300, 500]\n",
    "xVals = xVals = np.arange(1, 501)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gisette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_file = \"../data/Gisette/gisette_train.data\"\n",
    "y_train_file = \"../data/Gisette/gisette_train.labels\"\n",
    "\n",
    "x_valid_file = \"../data/Gisette/gisette_valid.data\"\n",
    "y_valid_file = \"../data/Gisette/gisette_valid.labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, trainErrors, testErrors = runModel(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotLosses(xVals, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotErrors(K, trainErrors, testErrors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genErrorTable(K, trainErrors, testErrors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dexter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_file = \"../data/dexter/dexter_train.csv\"\n",
    "y_train_file = \"../data/dexter/dexter_train.labels\"\n",
    "\n",
    "x_valid_file = \"../data/dexter/dexter_valid.csv\"\n",
    "y_valid_file = \"../data/dexter/dexter_valid.labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, trainErrors, testErrors = runModel(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotLosses(xVals, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotErrors(K, trainErrors, testErrors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genErrorTable(K, trainErrors, testErrors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Madelon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_file = \"../data/MADELON/madelon_train.data\"\n",
    "y_train_file = \"../data/MADELON/madelon_train.labels\"\n",
    "\n",
    "x_valid_file = \"../data/MADELON/madelon_valid.data\"\n",
    "y_valid_file = \"../data/MADELON/madelon_valid.labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, trainErrors, testErrors = runModel(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotLosses(xVals, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotErrors(K, trainErrors, testErrors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genErrorTable(K, trainErrors, testErrors)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
