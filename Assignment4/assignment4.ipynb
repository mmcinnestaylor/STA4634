{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAMES: Timothy Barao, Marlan McInnes-Taylor\n",
    "# FSUIDS: tjb13b, mm05f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(x_train_file, y_train_file, x_valid_file, y_valid_file):\n",
    "\n",
    "    with open(x_train_file) as file:\n",
    "        if \"Dexter\" in x_train_file:\n",
    "            x_train = pd.read_csv(file, delim_whitespace=False, header=None)\n",
    "        else:    \n",
    "            x_train = pd.read_csv(file, delim_whitespace=True, header=None)\n",
    "        x_train = x_train.to_numpy(dtype=np.float64)\n",
    "\n",
    "    with open(y_train_file) as file:\n",
    "        y_train = pd.read_csv(file, header=None)\n",
    "        y_train = y_train.to_numpy(dtype=np.float64)\n",
    "\n",
    "    with open(x_valid_file) as file:\n",
    "        if \"Dexter\" in x_valid_file:\n",
    "            x_valid = pd.read_csv(file, delim_whitespace=False, header=None)\n",
    "        else:    \n",
    "            x_valid = pd.read_csv(file, delim_whitespace=True, header=None)\n",
    "        x_valid = x_valid.to_numpy(dtype=np.float64)\n",
    "\n",
    "    with open(y_valid_file) as file:\n",
    "        y_valid = pd.read_csv(file, header=None)\n",
    "        y_valid = y_valid.to_numpy(dtype=np.float64)\n",
    "\n",
    "    N = x_train.shape[0]   # Rows\n",
    "    M = x_train.shape[1]   # Columns \n",
    "\n",
    "    # Standardize data\n",
    "    for i in range(0, M):\n",
    "        if (not np.any(x_valid[:, i])):\n",
    "            x_valid[:, i].fill(0)\n",
    "        else:  \n",
    "            x_valid[:, i] = (x_valid[:, i] - np.mean(x_valid[:, i]))/(np.std(x_valid[:, i]))\n",
    "            \n",
    "        if(not np.any(x_train[:, i])):\n",
    "            x_train[:, i].fill(0)\n",
    "        else:\n",
    "            x_train[:, i] = (x_train[:, i] - np.mean(x_train[:, i]))/(np.std(x_train[:, i]))\n",
    "    \n",
    "    # x_valid = np.insert(x_valid, 0, 1, axis=1)\n",
    "    # x_train = np.insert(x_train, 0, 1, axis=1)\n",
    "\n",
    "    y_valid = np.where(y_valid == -1, 0, y_valid)  \n",
    "    y_train = np.where(y_train == -1, 0, y_train)  \n",
    "    \n",
    "    print(\"X_train Objs: \", x_train.shape[0], \"X_train Feats: \", x_train.shape[1])\n",
    "    print(\"Y_train Objs: \", y_train.shape[0])\n",
    "    \n",
    "    print(\"\\nX_valid Objs: \", x_valid.shape[0], \"X_valid Feats: \", x_valid.shape[1])\n",
    "    print(\"Y_valid Objs: \", y_valid.shape[0])\n",
    "    \n",
    "    return x_train, y_train, x_valid, y_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penalty(x, lr):\n",
    "    indices = np.where(np.absolute(x) < lr) \n",
    "    mask = np.ones(x.shape, np.bool)\n",
    "    mask[indices] = 0\n",
    "\n",
    "    x[indices] = pow(lr,2) - np.power(x[indices] - lr, 2)\n",
    "    x[mask] = pow(lr,2)\n",
    "    \n",
    "    return x\n",
    "    # Penalty \n",
    "    # P_lr(X) = {lr^2 - (|x| - lr)^2     if |x| < lr}\n",
    "    #          {lr^2                    else       }\n",
    "    \n",
    "def log_like(X, Y, W,lr):\n",
    "    N = ((1)/(X.shape[0]))\n",
    "    x = N * (np.log(1 + np.exp(np.dot(-Y.flatten(), np.dot(X, W)))) + lr * penalty(W, lr).sum())\n",
    "    return x\n",
    "    \n",
    "    # Loss/log-likliehood\n",
    "    # L(W) = 1/N * np.log(1 + np.exp(-Y * W * X)) + lr * P_lr(W).sum()     #take sum of all penalties of W    \n",
    "    \n",
    "def updateWeights(data, labels, weights, lr):\n",
    "    N = x_train.shape[0]\n",
    "    weights = weights + (1/N * np.dot(data.T, (labels.flatten() - (1/(1 + np.exp(np.dot(-data, weights)  ))))))\n",
    "    weights[np.absolute(weights) <= lr] = 0\n",
    "    return weights\n",
    "\n",
    "    # Hybrid Penalties\n",
    "    # Hybrid(X, lr) =  {0    if |x| <= lr}   return array of each value   \n",
    "    #                  {x/1  if |x| > lr} \n",
    "\n",
    "    # Updating Weights\n",
    "    # w = w + 1/N * X * (Y - (1 / (1 + np.exp(-X * W))))\n",
    "    # w = Hybrid(w, lr)\n",
    "\n",
    "    \n",
    "def predict(samples, W):\n",
    "    prod = np.exp(W[0] + np.dot(samples, W))\n",
    "    pred_1 = prod / (1 + prod)\n",
    "    pred_0 = 1  / (1 + prod)\n",
    "   \n",
    "    return np.round(pred_1)    \n",
    "    # Predict \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x_train, y_train, W, lr):\n",
    "    L_i = []\n",
    "    for i in range(100):\n",
    "        W = updateWeights(x_train, y_train, W, lr)\n",
    "        L_i.append(log_like(x_train, y_train, W, lr))\n",
    "        print(\"\\rIteration: \" + str(i) + \" Non_zero weights: \" +  str(np.sum(W != 0.)), sep='', end='', flush=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gisette Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_file = \"Data/Gisette/gisette_train.data\"\n",
    "y_train_file = \"Data/Gisette/gisette_train.labels\"\n",
    "\n",
    "x_valid_file = \"Data/Gisette/gisette_valid.data\"\n",
    "y_valid_file = \"Data/Gisette/gisette_valid.labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'to_numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-589549577a97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_valid_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-e56fa8e87196>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(x_train_file, y_train_file, x_valid_file, y_valid_file)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelim_whitespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   4370\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4371\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4372\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4374\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'to_numpy'"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_valid, y_valid = load_data(x_train_file, y_train_file, x_valid_file, y_valid_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [1.0, 0.1, 0.001, 0.0001]\n",
    "errorGis = pd.DataFrame({\"Features\":[0, 0, 0, 0, 0], \"Training Error (%)\":[0, 0, 0, 0, 0], \"Test Error (%)\":[0, 0, 0, 0, 0]}, index=learning_rates)\n",
    "errorGis.index.name = \"Lambda\"\n",
    "for lr in learning_rates:                 \n",
    "    W = np.zeros(x_train.shape[1])\n",
    "    train(x_train, y_train, W, lr)\n",
    "    \n",
    "    preds = predict(x_train, W)    \n",
    "    missed = len(np.where(preds != y_train))\n",
    "    train_accuracy = (y_train.shape[0] - missed) / (y_train.shape[0])\n",
    "    \n",
    "    preds = predict(x_valid, W)    \n",
    "    missed = len(np.where(preds != y_valid))\n",
    "    valid_accuracy = (y_valid.shape[0] - missed) / (y_valid.shape[0])\n",
    "    \n",
    "    print(\"\\nlr: \" + str(lr) + \" Train Accuracy: \" +  str(train_accuracy *100.00),)\n",
    "    print(\"lr: \" + str(lr) + \" Valid Accuracy: \" +  str(valid_accuracy *100.00), \"\\n\")\n",
    "    \n",
    "    errorGis.loc[lr, 'Features'] = np.sum(W != 0.)\n",
    "    errorGis.loc[lr, 'Training Error (%)'] = round(100 - train_accuracy * 100, 2)\n",
    "    errorGis.loc[lr, 'Test Error (%)'] = round(100 - valid_accuracy * 100, 2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dexter Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_file = \"Data/Dexter/dexter_train.csv\"\n",
    "y_train_file = \"Data/Dexter/dexter_train.labels\"\n",
    "\n",
    "x_valid_file = \"Data/Dexter/dexter_valid.csv\"\n",
    "y_valid_file = \"Data/Dexter/dexter_valid.labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_valid, y_valid = load_data(x_train_file, y_train_file, x_valid_file, y_valid_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [1.0, 0.1, 0.001, 0.0001]\n",
    "errorDex = pd.DataFrame({\"Features\":[0, 0, 0, 0, 0], \"Training Error (%)\":[0, 0, 0, 0, 0], \"Test Error (%)\":[0, 0, 0, 0, 0]}, index=learning_rates)\n",
    "errorDex.index.name = \"Lambda\"\n",
    "for lr in learning_rates:                 \n",
    "    W = np.zeros(x_train.shape[1])\n",
    "    train(x_train, y_train, W, lr)\n",
    "    \n",
    "    preds = predict(x_train, W)    \n",
    "    missed = len(np.where(preds != y_train))\n",
    "    train_accuracy = (y_train.shape[0] - missed) / (y_train.shape[0])\n",
    "    \n",
    "    preds = predict(x_valid, W)    \n",
    "    missed = len(np.where(preds != y_valid))\n",
    "    valid_accuracy = (y_valid.shape[0] - missed) / (y_valid.shape[0])\n",
    "    \n",
    "    print(\"\\nlr: \" + str(lr) + \" Train Accuracy: \" +  str(train_accuracy *100.00),)\n",
    "    print(\"lr: \" + str(lr) + \" Valid Accuracy: \" +  str(valid_accuracy *100.00), \"\\n\")\n",
    "    \n",
    "    errorDex.loc[lr, 'Features'] = np.sum(W != 0.)\n",
    "    errorDex.loc[lr, 'Training Error (%)'] = round(100 - train_accuracy * 100, 2)\n",
    "    errorDex.loc[lr, 'Test Error (%)'] = round(100 - valid_accuracy * 100, 2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Madelon Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_file = \"Data/Madelon/madelon_train.data\"\n",
    "y_train_file = \"Data/Madelon/madelon_train.labels\"\n",
    "\n",
    "x_valid_file = \"Data/Madelon/madelon_valid.data\"\n",
    "y_valid_file = \"Data/Madelon/madelon_valid.labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_valid, y_valid = load_data(x_train_file, y_train_file, x_valid_file, y_valid_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [1.0, 0.1, 0.001, 0.0001]\n",
    "errorMad = pd.DataFrame({\"Features\":[0, 0, 0, 0, 0], \"Training Error (%)\":[0, 0, 0, 0, 0], \"Test Error (%)\":[0, 0, 0, 0, 0]}, index=learning_rates)\n",
    "errorMad.index.name = \"Lambda\"\n",
    "for lr in learning_rates:                 \n",
    "    W = np.zeros(x_train.shape[1])\n",
    "    train(x_train, y_train, W, lr)\n",
    "    \n",
    "    preds = predict(x_train, W)    \n",
    "    missed = len(np.where(preds != y_train))\n",
    "    train_accuracy = (y_train.shape[0] - missed) / (y_train.shape[0])\n",
    "    \n",
    "    preds = predict(x_valid, W)    \n",
    "    missed = len(np.where(preds != y_valid))\n",
    "    valid_accuracy = (y_valid.shape[0] - missed) / (y_valid.shape[0])\n",
    "    \n",
    "    print(\"\\nlr: \" + str(lr) + \" Train Accuracy: \" +  str(train_accuracy *100.00),)\n",
    "    print(\"lr: \" + str(lr) + \" Valid Accuracy: \" +  str(valid_accuracy *100.00), \"\\n\")\n",
    "    \n",
    "    errorMad.loc[lr, 'Features'] = np.sum(W != 0.)\n",
    "    errorMad.loc[lr, 'Training Error (%)'] = round(100 - train_accuracy * 100, 2)\n",
    "    errorMad.loc[lr, 'Test Error (%)'] = round(100 - valid_accuracy * 100, 2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorTableFull = pd.concat([errorGis, errorDex, errorMad])\n",
    "errorTableFull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commented Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #x_train = (x_train - np.mean(x_train, axis=0)) / np.std(x_train, axis=0)\n",
    "    #x_valid = (x_valid - np.mean(x_valid, axis=0)) / np.std(x_valid, axis=0)\n",
    "    \n",
    "    # if columns are 0, return 0\n",
    "                \n",
    "            \n",
    "        \n",
    "        #x_valid = np.insert(x_valid, 0, 1, axis=1)\n",
    "        #x_train = np.insert(x_train, 0, 1, axis=1)\n",
    "\n",
    "    #y_valid = np.where(y_valid == -1, 0, y_valid)  \n",
    "    #y_train = np.where(y_train == -1, 0, y_train)   \n",
    "    \n",
    "                       \n",
    "    #print(\"\\n\\n=-=-=-=-=-=-=-= x_valid =-=-=-=-=-=-=-= \")\n",
    "    #print(\"Col: \", i, \" mean: \", x_valid[:, i].mean())\n",
    "    #print(\"Col: \", i, \" std: \", x_valid[:, i].std())\n",
    "\n",
    "\n",
    "    #print(\"=-=-=-=-=-=-=-= x_train =-=-=-=-=-=-=-= \")\n",
    "    #print(\"Col: \", i, \" mean: \", x_train[:, i].mean())\n",
    "    #print(\"Col: \", i, \" std: \", x_train[:, i].std())   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
